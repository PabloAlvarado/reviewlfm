
Consider the control problem

  df/dt = A_f f + M_f c
   J[c] = 1/2 f^T(T) Psi f(T) + int [f^T(t) X(t) f(t) + c^T(t) U(t) c(t)] dt

The solution is

   dK_f/dt = -A_f^T K_f - K_f A_f + K_f M_f U^{-1} M_f^T K_f - X
    K_f(T) = Psi

  c = -U^{-1} M_f^T K_f f

the infinite-time LQ is then given by dK_f/dt = 0. 

******************* 

Consider the LFM problem

  df/dt = A_f f + B_f C_u u + M_f c
  du/dt = A_u u + B_u w

which corresponds to g = [f;u]

  dg/dt = A g + M c

with

 A = [A_f  B_f C_u;
        0     A_u]

  M = [M_f;
        0  ]

  C_g = [I;
         0]

Let us now consider the LQ control problem

  J[c] = 1/2 f^T(T) Psi f(T) + int [f^T(t) X(t) f(t) + c^T(t) U(t) c(t)] dt

which can be rewritten as

  J[c] = 1/2 g^T(T) Psi_g f(T) + int [g^T(t) X_g(t) g(t) + c^T(t) U(t) c(t)] dt

where

   Psi_g = [Psi  0; 0 0]
  X_g(t) = [X(t) 0; 0 0]

The solution is now

   dK/dt = -A^T K - K A + K M U^{-1} M^T K - X_g
    K(T) = Psi_g

  c = -U^{-1} M^T K g

However, putting K = [K11 K12; K21 K22] with K21 = K12^T, we have

A^T K =
  [A_f^T*K11  A_f^T*K12
   C_u^T*B_f^T*K11+A_u^T*K21  C_u^T*B_f^T*K12+A_u^T*K22]

K*A =
  [K11*A_f  K11*B_f*C_u+K12*A_u
   K21*A_f  K21*B_f*C_u+K22*A_u]

K M U^{-1} M^T K = 
  [K11*M_f*U^{-1}*M_f^T*K11,  K11*M_f*U^{-1}*M_f^T*K12
   K21*M_f*U^{-1}*M_f^T*K11,  K21*M_f*U^{-1}*M_f^T*K22]

Thus we have

  dK11/dt
  = -A_f^T*K11 - K11*A_f
  + K11*M_f*U^{-1}*M_f^T*K11
  dK12/dt
  = -A_f^T*K12 - K11*B_f*C_u - K12*A_u
  + K11*M_f*U^{-1}*M_f^T*K12
  dK21/dt
  = -C_u^T*B_f^T*K11 - A_u^T*K21 - K21*A_f
  + K21*M_f*U^{-1}*M_f^T*K11
  dK22/dt
  = -C_u^T*B_f^T*K12 - A_u^T*K22 - K21*B_f*C_u - K22*A_u
  + K21*M_f*U^{-1}*M_f^T*K12

  K(T) = [Psi  0; 0 0]

Clearly the equation for K11 is exactly the equation for K_f(t) hence K11 = K_f. Let us look at

  dK12/dt
  = -A_f^T*K12 - K11*B_f*C_u - K12*A_u + K11*M_f*U^{-1}*M_f^T*K12

which does not allow for a easy solution.

However, in the case of infinite regulation we have
  
  0 = -A_f^T*K12 - K11*B_f*C_u - K12*A_u + K11*M_f*U^{-1}*M_f^T*K12
  0 = (K11*M_f*U^{-1}*M_f^T-A_f^T)*K12 - K12*A_u - K11*B_f*C_u 
  (K11*M_f*U^{-1}*M_f^T-A_f^T)*K12 - K12*A_u = K11*B_f*C_u 

which is a sylvester equation and hence numerically solvable.

For K22 we get

  0 = -C_u^T*B_f^T*K12 - A_u^T*K22 - K21*B_f*C_u - K22*A_u
  + K21*M_f*U^{-1}*M_f^T*K12

  A_u^T*K22 + K22*A_u
  = K21*M_f*U^{-1}*M_f^T*K12 - C_u^T*B_f^T*K12 - K21*B_f*C_u

  A_u^T*K22 + K22*A_u
  = K12'*M_f*U^{-1}*M_f^T*K12 - C_u^T*B_f^T*K12 - K12'*B_f*C_u

which again is a sylvester equation (also a lyapunov equation).

The gain is given as

  G = U^{-1} [M_f'*K11  M_f'*K12]

where the left-hand part is the basic LQ gain.


--- appendix

K*A =
  [K11 K12  [A_f  B_f C_u;
   K21 K22]    0     A_u]
  =
  [K11*A_f  K11*B_f*C_u+K12*A_u
   K21*A_f  K21*B_f*C_u+K22*A_u]

(K*A)^T = 
  [A_f^T*K11  A_f^T*K12
   C_u^T*B_f^T*K11+A_u^T*K21  C_u^T*B_f^T*K12+A_u^T*K22]

[M_f;
  0]  iU [M_f^T 0]
= [M_f*iU;
      0] [M_f^T 0]
= [M_f*iU*M_f^T 0;
      0         0]

[K11 K12;  [M_f*iU*M_f^T 0;
 K21 K22]      0         0]
=
[K11*M_f*iU*M_f^T  0;
 K21*M_f*iU*M_f^T  0]

[K11*M_f*iU*M_f^T  0; [K11 K12;
 K21*M_f*iU*M_f^T  0]  K21 K22]
=
[K11*M_f*iU*M_f^T*K11 K11*M_f*iU*M_f^T*K12;
 K21*M_f*iU*M_f^T*K11 K21*M_f*iU*M_f^T*K12]



>> syms K11 K12 K21 K22 A_f A_u C_u B_f M_f iU real;
>> K = [K11 K12; K21 K22];
>> A = [A_f B_f*C_u; 0 A_u];
>> M = [M_f; 0];
>> K*A
 
ans =
 
[ A_f*K11, A_u*K12 + B_f*C_u*K11]
[ A_f*K21, A_u*K22 + B_f*C_u*K21]
 
>> A'*K
 
ans =
 
[               A_f*K11,               A_f*K12]
[ A_u*K21 + B_f*C_u*K11, A_u*K22 + B_f*C_u*K12]
 
>> K*M*iU*M'*K
 
ans =
 
[   K11^2*M_f^2*iU, K11*K12*M_f^2*iU]
[ K11*K21*M_f^2*iU, K12*K21*M_f^2*iU]


G = U^{-1} M^T K
= U^{-1} [M_f' 0] [K11 K12
                   K21 K22]
= U^{-1} [M_f'*K11  M_f'*K12]
          

******************* 



******************* 

Assume that we have an LTI system

  df/dt = A f + L u

which is drive by a stationary GP

  u(t) ~ GP(0,k(t-t'))
  
The solution to ODE is then given as

  f(t) = exp(A (t-t0)) f(t0) + int_t0^t exp(A (t-tau)) u(t) dt

Taking the limit t0 -> infty then gives

  f(t) = int_{-infty}^t exp(A (t-tau)) u(t) dt

The covariance function is then given as

  E[f(t) f^T(t')]
  = E[ { int_{-infty}^t exp(A (t-tau)) L u(tau) dtau }
       { int_{-infty}^t' exp(A (t'-tau')) L u(tau') dtau' }^T ]
  = E[
  int_{-infty}^t' int_{-infty}^t exp(A (t-tau)) L u(tau) u(tau')^T L^T exp(A (t'-tau'))^T dtau dtau'
     ]
  = int_{-infty}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau'
  = int_{-infty}^t' int_{-infty}^t U(t-tau) L k(tau-tau') L^T U^T(t'-tau') dtau dtau'

The cross covariance between f and u is

  E[f(t) u^T(t')]
  = E[ { int_{-infty}^t exp(A (t-tau)) L u(tau) dtau }
       { u^T(t') ]
  = int_{-infty}^t exp(A (t-tau)) L E[u(tau) u(t')] dtau
  = int_{-infty}^t exp(A (t-tau)) L k(tau,t') dtau
  = int_{-infty}^t U(t-tau) L k(tau,t') dtau

Let's now attempt to simplify these. Note that because of stationarity we have

  E[f(t) f^T(t)]
  = int_{-infty}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t-tau))^T dtau dtau'
  = C,

which is independent of C. If t <= t' we now have

  = int_{-infty}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau'
  = int_{-infty}^t int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau'
  + int_{t}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau'

For the first term we get

  = int_{-infty}^t int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t' - t + t -tau'))^T dtau dtau'
  = int_{-infty}^t int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t - tau'))^T dtau dtau' exp(A (t'-t))
  = C exp(A (t'-t))

The second term is harder though:

  int_{t}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau'

Let try another technique. We have

  E[f(t) f^T(t')]
  = int_{-infty}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau'

Thus the Leibniz rule gives

  d/dt' E[f(t) f^T(t')]
  = int_{-infty}^t' int_{-infty}^t exp(A (t-tau)) L k(tau-tau') L^T exp(A (t'-tau'))^T dtau dtau' A^T 
  + int_{-infty}^t exp(A (t-tau)) L k(tau-t') L^T exp(A (t'-t'))^T dtau
  = E[f(t) f^T(t')] A^T 
  + int_{-infty}^t exp(A (t-tau)) L k(tau-t') dtau L^T 

The derivative for the second term is given as

  d/dt' int_{-infty}^t exp(A (t-tau)) L k(tau-t') dtau L^T
  = int_{-infty}^t exp(A (t-tau)) L dk/dt'(tau-t') dtau L^T

******************* 

Consider

  d2f/dt2 + d2f/dx2 = u

which naively would correspond to

  d2f/dt2 = -d2f/dx2 + u

or

  df1/dt = f2
  df2/dt = -d2f/dx2 + u

which unfortunately is not stable.

The spectral density can be solved as

  -wt^2 F - wx^2 F = U
  F = -U/(wt^2 + wx^2)
  S = S_u/(wt^2 + wx^2)^2

which gives the denominator roots

        wt^2 + wx^2 = 0
  -(iwt)^2 + wx^2 = 0
  (iwt)^2 = wx^2
  iwt = +- sqrt(wx^2)
      = +- sqrt(-(iwx)^2)
      
Thus the stable part is

  G(iwt) = 1 / (iwt + sqrt(-(iwx)^2))^2
  = 1 / ((iwt)^2 + 2 sqrt(-(iwx)^2) (iwt) - (iwx)^2)

which corresponds to

  d2f/dt2 + 2 sqrt(-nabla^2) df/dt - nabla^2 f = u

i.e.

  dvf/dt = [0 1; nabla^2  -2 sqrt(-nabla^2)] vf + [0;1] u

However, this is not entirely equivalent, because we have now some an
unitary transformation on u as well. Recall that originally we have

  [(i wt)^2 + (i wx)^2] F = U

and the latter equation is actually

  [iwt + sqrt(-(iwx)^2))]^2 F = tU

What we can do is now to multiply with

  H(iw,iwx) = [(i wt)^2 + (i wx)^2] / [iwt + sqrt(-(iwx)^2))]^2

to give

  [(i wt)^2 + (i wx)^2] F = H(iw,iwx) Ut

Thus we should apply the operator H onto the input estimate to get it
right. What does the operator look like then? Let us put

  A = -(i wx)^2 = wx^2 =~ lap_e
  B = sqrt(-(iwx)^2)) = |wx| =~ sqrt(lap_e)

which both are positive operators. Thus

  Z = [(i wt)^2 - A] / [iwt + B]^2 U
    = [(i wt)^2 - A] / [(iwt)^2 + 2 (iwt) B + B^2] U
    = [(i wt)^2 + 2 (iwt) B + B^2 - A - 2 (iwt) B - B^2]
    / [(iwt)^2 + 2 (iwt) B + B^2] U
    = { 1 - [2 B (iwt) + A + B^2] / [(iwt)^2 + 2 (iwt) B + B^2] } U

which whose second part can be realized as a state-space system

  dx/dt = [0 1; -B^2 -2B] x + [0;1] u
      z = [(A+B^2)  2B] x

** Obsevability and controllability

* Intuition

We have something like

  df/dt = A_f f + B_f C_u u
  du/dt = A_u u + B_u w
      y = C_f f + e_k

where we can ensure that we observe f from y. In a certain sense, we can then also "observe"

  n = B_f C_u u

or because B_f is often non-square, we actually observe

  n = C_u u

The in addition to observability of [A_f,C_f], the requirement should be the observability of [A_u,C_u], that is, the observability of the system

  du/dt = A_u u
      y = B_f C_u u

We should though have such B_f which let's the information in u to fully flow into state f. One way to ensure this is to require that (B_f^T B_f)^{-1} B_f^T is non-singular, which basically means that B_f^T B_f has a bounded inverse. This might be possible to convert into some kind of controllability condition. However, the observability with n = B_f C_u u should be fine as well.


* Definitions

Observability of [F_k,G_k] means that the following matrix is positive definite:

  O_{k,l} = sum_{i=l}^k Psi_{i-1,l}^T G_i^T G_i Psi_{i-1,l}

where Psi_{i-1,l} = prod_{i=l}^{i-1}Â F_i. The controllability matrix is

  C_{k,l} = sum_{i=l}^k Psi_{k-1,i+1} G_i G_i^T Psi_{k-1,i+1}^T

Consider the discrete-time system

  f_k = A_k f_{k-1} + B_k u_k
  y_k = H_k f_k + r_k

This is observable, if [A_k,R^{-1/2} H_k] is and controllable if [A_k,B_k] is and we have

  O_{k,l} = sum_{i=l}^k Phi_{k,l}^T H_i^T R^{-1} H_i Phi_{k,l}
  C_{k,l} = sum_{i=l}^{k-1} Phi_{k,i+1} B_i B_i^T Phi_{k,i+1}^T

If R is bounded below and above we can basically consider

  O_{k,l} = sum_{i=l}^k Phi_{k,l}^T H_i^T H_i Phi_{k,l}
  C_{k,l} = sum_{i=l}^{k-1} Phi_{k,i+1} B_i B_i^T Phi_{k,i+1}^T

and the observability of [A_k,H_k] is basically equivalent to controllability of [A_k^T,H_k^T]. 

Recall that the system

  dg/dt = A g
    y_k = C y(t_k) + eps

or

  g_k = exp(A Dt_k) g_{k-1}
  y_k = C y(t_k) + eps

is uniformly observable if there exist N such the following matrix is positive definite and uniformly bounded for k >= N:

  J_k = sum_{i=1}^k exp(A (t_i - t_k))^T C^T R_i^{-1} C exp(A (t_i - t_k)) 

which somewhat equivalent to boundedness of

  tJ_k = sum_{i=1}^k exp(A t_i)^T C^T R_i^{-1} C exp(A t_i) 

Furthermore a discrete system

  g_k = exp(A Dt_k) g_{k-1} + Gamma_k c_{k-1}

is uniformly controllable w.r.t. noise if the following matrix is similarly bounded:

  G_k = sum_{i=0} exp(A (t_k - t_{i+1}))^T Gamma_k Q_k Gamma_k^T exp(A (t_k - t_{i+1})) 

**

Let us consider the composite continuous-time system

  du/dt = A_u u + B_u w
  df/dt = A_f f + B_f C_u u
      y = C_f f

Note that the system is essentially a composition of two transfer functions for the systems

     du/dt = A_u u + B_u input_u
  output_u = C_u u
     df/dt = A_f f + B_f input_f
    output_f = C_f f

i.e.

  Output_U = H_U Input_U
  Output_F = H_F Input_F

Then the composite system is (continuous-time) observable and controllable if the subsystems are and if no pole of H_F is a zero of H_U and vice versa. [should find reference for this - but this only works for single latent force and measurement!] [IS THIS REALLY EVEN TRUE, PROBABLY NOT?]

http://www.ece.rutgers.edu/~gajic/psfiles/chap5.pdf

http://www.ece.rutgers.edu/~gajic/psfiles/chap5traCO.pdf

Then the corresponding discrete-time system will be controllable and observable provided that the sampling rate is non-pathological:

Ding, F., Qiu, L., & Chen, T. (2009). Reconstruction of continuous-time systems from their non-uniformly sampled discrete-time systems. Automatica, 45(2), 324-332.
http://www.sciencedirect.com.libproxy.aalto.fi/science/article/pii/S0005109808004457

which seems to be based on the book of Chen/Francis (1996) and article of Kalman (1963).


Some results on the observability and controllability of composite systems:

Chen, C. T., & Desoer, C. (1967). Controllability and observability of composite systems. IEEE Transactions on Automatic Control, 12(4), 402-409.

Davison, E., & Wang, S. (1975). New results on the controllability and observability of general composite systems. IEEE Transactions on Automatic Control, 20(1), 123-128.
http://ieeexplore.ieee.org.libproxy.aalto.fi/stamp/stamp.jsp?arnumber=1100857

which use e.g. theorems from

H.H. Rosenbrock, âState-Space and Multivariable Theory,â T. Nelson, London, 1970.


Counter-examples of non-sufficiency of cascade observability of both systems is given in
Gilbert, E. G. (1963). Controllability and observability in multivariable control systems. Journal of the Society for Industrial and Applied Mathematics, Series A: Control, 1(2), 128-151.
The paper also discusses the property that pole-zero cancellation will make the system unobservable
http://people.duke.edu/~hpgavin/SystemID/References/Gilbert-JSIAM-1963.pdf

A problematic case is e.g.

  H_U = 1 / (1 + s)
  H_F = (1 + s) / (1 + 2s + s^2)

which is

  du/dt = -u + w
  df/dt = [0 1; -1 -2] f + [0;1] u
      y = [1 1] f

Note that the poles of system

  dg/dt = A g + B u
      y = C g

are given by eigenvalues of A and the zeros are determined via

  det([Is-A B; -C 0]) = 0

which works only if we have a single latent force model.

Something is here:

https://www.researchgate.net/publication/245320516_Poles_and_zeros_of_linear_multivariable_systems_A_survey_of_the_algebraic_geometric_and_complex-variable_theory

For u above we get

  eig([-1]) = -1 (one pole)
  det([s+1 1; -1 0]) = 1 (no zeros)

For f we get

  eig([0 1; -1 -2]) = [-1 -1] (double pole)
  det([s*eye(2)-[0 1; -1 -2] ([0;1]); -[1 1] 0]) = s + 1 (zero at -1)

Thus provided that for all eigenvalues lambda^u_i of A_u we have det([Is-A_f -B_f; C_f 0]) != 0 and for all eigenvalues lambda^f_j of A_f we have det([Is-A_u -B_u; C_u 0]) != 0 then the system is observable.

**

In Davidson & Wang we have the following.

The system

  [dx1/dt]   [ A1 E  ] [ x1 ]   [ B1 ]
  [      ] = [       ] [    ] + [    ] u
  [dx2/dt]   [ 0  A2 ] [ x2 ]   [ B2 ]

              [ x1 ]
  y = [C1 C2] [    ] 
              [ x2 ]

with x1 \in R^n1, x2 \in R^n2 is controllable if

a) (A2,B2) is controllable

       [ A1 - lam_i^1 I       E        B1  ]
b) rank[                                   ] = n1 + n2
       [    0            A2 - lam_^1 I  B2 ]

for all eigenvalues lam_i^1 of A1

and observable if

c) (C1,A1) is observable

       [ A1 - lam_i^2 I       E        ]
       [                               ]
d) rank[    0            A2 - lam_^2 I ] = n1 + n2
       [                               ]
       [    C1                C2       ]

In our control case we have B2 = 0 and hence (A2,B2) is not controllable not the full system. 

In the estimation case we can assume (C1,A1) to be observable. 


** 

We can also directly consider continuous-time observability and controllability conditions for 

  df/dt = A_f f + B_f C_u u
  du/dt = A_u u + B_u w
      y = C_f f

with

  A = [A_f  B_f*C_u;
       Au      0    ]

  B = [ 0
       B_u]

  C = [C_f 0]

We can now write

  [C; C*A; C*A^2; ...]
  = [C_f 0;
     C_f*Af C_f*Au;
     ...];

In our example we have

  A = [ 0 1  0;
       -1 -1 1;
       -1 0 0 ]
  B = [0;
       0;
       1]

  C = [1 1 0]

>> rank([C; C*A; C*A^2])

ans =

     2

>> rank([B A*B A^2*B])

ans =

     3

Thus the system is not observable.


**



**

We have

  df/dt = A_f f + B_f C_u u 
  du/dt = A_u u + B_u w
    y_k = C_f f(t_k) + e_k

Let us now consider

  U(t) = expm([A_f   B_f C_u]
              [0      A_u   ] t)

It turns out that this will have the form

  U(t) = [ exp(A_f t)   Gamma(t)   ]
         [    0         exp(A_u t) ],

Note that for noise-free system we get

   u(t) = exp(A_u (t-t_0)) u(t_0)
   f(t) = exp(A_f (t-t_0)) f(t_0) + int_{t_0}^t exp(A_f (t-s)) B_f C_u u(s) ds
        = exp(A_f (t-t_0)) f(t_0) + int_{t_0}^t exp(A_f (t-s)) B_f C_u exp(A_u (s-t_0)) u(t_0) ds 

Thus Gamma(t) is given as

  Gamma(t) = int_0^t exp(A_f (t-s)) B_f C_u exp(A_u s) ds

Thus the corresponding discrete-time system is

  f_k = exp(A_f Dt_k) f_{k-1} + Gamma(Dt_k) u_{k-1} + q^f_k
  u_k = exp(A_f Dt_k) f_{k-1} + q^u_k
    y_k = C_f f_k + e_k

where we can ignore the noises q^f_k and q^u_k in the observability analysis. 

The observability matrix has the form

  J_k = sum_{i=1}^k exp(A (t_i - t_k))^T C^T R_i^{-1} C exp(A (t_i - t_k)) 
  = sum_{i=1}
       [ exp(A_f (t_i - t_k))^T         0               ]
       [ Gamma (t_i - t_k)^T    exp(A_u (t_i - t_k))^T  ]
     * [ C_f^T ]
       [   0   ]
     * R_i^{-1}
     * [ C_f  0 ]
     * [ exp(A_f (t_i - t_k))   Gamma (t_i - t_k)       ]
       [    0         exp(A_u (t_i - t_k))              ]
  = sum_{i=1}
       [ exp(A_f (t_i - t_k))^T C_f^T ]
       [ Gamma (t_i - t_k)^T C_f^T    ]
     * R_i^{-1}
     * [ C_f exp(A_f (t_i - t_k))   C_f Gamma (t_i - t_k)  ]
  = sum_{i=1} [A_11 A_12; A_12^T A_22],

where

  A_11 = exp(A_f (t_i - t_k))^T C_f^T R_i^{-1} C_f exp(A_f (t_i - t_k))
  A_12 = exp(A_f (t_i - t_k))^T C_f^T R_i^{-1} C_f Gamma (t_i - t_k)
  A_22 = Gamma (t_i - t_k)^T C_f^T R_i^{-1} C_f Gamma (t_i - t_k)

We thus have something like

  sum_{i=1}^k [F_i^T F_i   F_i^T G_i
               G_i^T F_i   G_i^T G_i]

and we already know that

  beta_1 I < sum_{i=1}^k F_i^T F_i < beta_2 I

for some beta_1,beta_2 \in (0,oo). The first attempt would be to try to bound

  beta_3 I < sum_{i=1}^k G_i^T G_i < beta_4 I

We would then expect that this implies the required identity. This is equivalent to the uniform observability of the system

  z_k = Gamma(Dt_k) z_{k-1}
  y_k = C_f z_k + eps

where

  Gamma(t) = int_0^t exp(A_f (t-s)) B_f C_u exp(A_u s) ds

or via duality, the uniform controllability of the following system (provided that the controllability matrix is suitably bounded):

  z_k = Gamma(Dt_k)^T z_{k-1} + C_f^T c_k

The corresponding identity for Dt -> 0 is slightly strage cause

  lim_{t->0} Gamma(t) = 0

instead I as we would expect. 

The continuous time version of the original model would be

  dg/dt = A g + B w
      y = C f + noise

for which the observability just means the rank condition

  rank[ C^T  A^T C^T  (A^T)^2 C^T + ... + (A^T)^{n-1} C^T ] = n

If we have

  df/dt = A_f f + B_f C_u u 
  du/dt = A_u u + B_u w
      y = C_f f + noise

Then

  C^T = [C_f^T;
           0   ]
  A^T = [   A_f^T       0;
         C_u^T B_f^T  A_u^T]

which is not so much easier.

Let us now return to where we were. Recall that we can also bound a matrix Q by bounding expressions of the form

  x^T Q x,

where |x| = 1. This is because the eigenvalues bound the possible values of this equation.

Let is now put for |[z;w]|^2 = |z|^2 + |w|^2 = 1 and compute

  [z^T w^T] [F_i^T F_i   F_i^T G_i
             G_i^T F_i   G_i^T G_i] [z;w]

  = z^T F_i^T F_i z + z^T F_i^T G_i w + w^T G_i^T F_i z + w^T G_i^T G_i w
  = z^T F_i^T F_i z + 2 z^T F_i^T G_i w + w^T G_i^T G_i w



which is essentially

  = a^T a + 2 a^T b + b^T b
  <= a^T a + 2 |a^T b| + b^T b
  <= a^T a + 2 |a| |b| + b^T b
  <= (|a| + |b|)^2

We also have

  2 |a|^2 + 2 |y|^2 = |a + b|^2 + |a - b|^2
  
Jensen's inequality 


We have

  [A1 B1] [A2 B2]
  [0  C1] [0  C2]
  = [A1*A2 A1*B2+B1*C2;
      0    C1*C2]

  K [Cf 0] [f;u] = K Cf f

We first discretize the system at arbitrary time points. The discretized system is

  g_k = U(\Delta t) g_{k-1} + q_k
  y_k = C g_k + e_k

which will be detectable provided that there exists a bounded gain sequence K_k such that tg_k = (U(\Delta t) - K_k C) tg_k is exponentially stable [see e.g. Anderson/Moore]. More explicitly, the following system needs to be exponentially stable with some choice of sequence K_k:

  tf_k = exp(A_f \, \Delta t_k) tf_{k-1} + \Gamma_k tu_{k-1} - K_k C_f tf_{k-1}
  tu_k = exp(A_u \, \Delta t_k) tu_{k-1} 

As the process u_k is exponentially stable, the sequence tu_k is exponentially decreasing and bounded. Hence it does not affect the stability of the first equation. Therefore, the full system will be detectable provided that there exists a gain sequence K_k such that tf_k = (exp(A_f \, \Delta t_k) - K_k C_f) tf_{k-1} is exponentially stable. The gain sequence exists, because [exp(A_f \, \Delta t_k),C_f] is detectable by assumption. 

Remark. Even though latent force models are detectable, they are not observable due to the unobservable latent force component. [UNTRUE!]


* Stabilizability

The controlled system is

  dg/dt = A g + B w + M c

The system is stabilizable if there exist a finite gain K_c such that the system dtg/dt = (A tg + M K_c) tg is exponentially stable [see e.g. Wonham]. More explicitly we should have

  dtf/dt = (A_f + M_u K_f) tf + (B_f*C_u + M_u K_u) tu
  dtu/dt = A_u tu

where we have written K_c = [K_f K_u]. Because tu does not infer the control of tf, and it is bounded, we can safely set K_u = 0. The remainder of the system will be stabilizable if there exists a gain K_f such that dtf/dt = (A_f + M_u K_f) tf is exponentially stable. By our assumption of the stabilizability of [A_f,M_f], this is true and hence the result follows.

Remark. Although the latent force is stabilizable it is not controllable, bacause we cannot control the latent GP. 

**

Let

  dg/dt = A g + B w,

and let P_oo be the solution to

  A P_oo + P_oo A^T + B q_c B^T = 0

Then we have

  E[g(t) g^T(t+tau)]
    { P_oo exp(A tau)^T, if tau >= 0
  = {
    { exp(-A tau) P_oo,  if tau < 0

Let the process

  dg(t)/dt = A g(t) + B w(t)
      g(t) = C g(t)
       
have a covariance function k_t(t,t'). Then the process

  dg(x,t)/dt = A g(x,t) + B w(x,t)
      f(x,t) = C g(x,t)

where E[w(x,t) w(x',t')] = q_c(x,x') delta(t-t') has the covariance function

  k(x,t;x',t') = q_(x,x') k_t(t,t')
    { P_oo exp(A tau)^T q_c(x,x'), if tau >= 0
  = {
    { exp(-A tau) P_oo q_c(x,x'),  if tau < 0

proof: We have

  g(x,t) = C_f int_{-oo}^t exp(A (t-s)) B w(x,s) ds

thus

  E[f(x,t) f^T(x',t')]
  = E[ C_f {int_{-oo}^t exp(A (t-s)) B w(x,s) ds}
     * {int_{-oo}^t' exp(A (t'-s')) B w(x',s') ds'}^T C^T ]
  = C_f int_{-oo}^min(t,t') exp(A (t-s)) B q_c(x,x') B^T exp(A (t'-s))^T ds C^T
  = k_t(t,t') q_c(x,x')

**

Let us consider

  df/dt = A_f f + B_f u
  du/dt = A_u u + B_u w
      f = C_f f

where A_f might not be stable. The stationary solution for u is indeed

  k(t - t') = { ...

which can be forced by putting u(0) ~ N(0,P^u_oo).

Let

  f(0) ~ N(0,P_0)
  u(0) ~ N(0,P^u_oo)

then with g(0) = [f(0); u(0)]

  g(t) = exp(t A) g(0) + int_0^t exp((t-s) A) B w(s) ds

and thus

  E[g(t) g^T(t')]
  = E[ { exp(t A) g(0) + int_0^t exp((t-s) A) B w(s) ds }
     * { exp(t' A) g(0) + int_0^t' exp((t'-s') A) B w(s') ds' }^T ]
  = exp(t A) E[ g(0) g^T(0) ] exp(t' A)
  + int_0^min(t,t') exp((t-s) A) B q_c B^T exp((t'-s) A)^T ds
  = exp(t A) blkdiag(P_0,P^u_oo) exp(t' A)
    { int_0^t exp((t-s) A) B q_c B^T exp((t-s) A)^T ds exp((t'-t) A)^T, if t <= t'
  + { 
    { exp((t-t') A) int_0^t' exp((t'-s) A) B q_c B^T exp((t'-s) A)^T ds, if t > t'
  = exp(t A) blkdiag(P_0,P^u_oo) exp(t' A)
    { Q(t) exp((t'-t) A)^T, if t <= t'
  + { 
    { exp((t-t') A) Q(t'), if t > t'

where Q(t) was defined in (49) and can be efficently computed with matrix fractions. This representation could further be simplified by using the fact that u(t) is stationary also in this joint model. 

****

In this section, our aim is to discuss the detectability and observability of the latent force models. For the theorems, we need to assume that the joint force system has a state-space representation, because otherwise the classical observability and detectability results \simo{ref Kalman \& Anderson} are not applicable. That is, we assume that we have a latent force model which has the following state space representation

[State space model here again]

We assume that

1. The physical system part, without the latent force, that is

  df/dt = A_f f + B_c c
      y = C_f f

is observable.

2. State state-space representation for the force is observable:

  du/dt = A_u u + B_u w
      z = C_u u

3. The system is not critically sampled.

Note that the observablity of the physical system and the latent force model separately does not imply that the full system would be observable. This is because there might be pole-zero cancellations which would make it impossible to separate the physical state from the latent force.

Clearly, if we wished to determine the detectability or observability of the given state-space representation above, then all we would need to do is a standard detectability or observability test \simo{ref. e.g. Kalman \& Anderson} directly on the joint system. However, for pratical reasons it would be desirable to be able to express these properties of the full system as function of the properties of the physical model and the GP. It turns our that this is, in general, possible for detectability, but for the observability it is hard to come up with a general theorem. Furthermore, both of these properties generally depend on the way that the system is sampled, which is to be expected, because we are still restricted by the sampling theorems of Shannon and Nyquist. For the detectability we get the following.

[The theorem here without the model]

Above, in Theorem III.1 we had to assume that detectability of the discretized system []. There are many ways to assure that, but one way is to demand that the continuous physical model is observable and that we are not sampling critically [ref], that is, in a way that would lead to aliasing of frequencies as in the Shannon-Nyquist theory. Although observability is a quite strong condition compared to detectability, it assures that we have the chance to reconstruct the physical system with an arbitrary precision by improving the measurement protocol, which would not be true for mere detectability. Based on this, we have the following theorem.

[Theorem with detectable GP, continuous-observable ODE and non-critically sampled system [ref], which leads to detectable joint system]

In general, the best way to determine the observability of the joint system is not to attempt to think of the ODE and GP separately, but explicitly consider the joint state-space model. There are numerous attempts to map the properties of this kind cascaded systems to the properties of the joint system \citep{cite a few}, but still the best way to go seems to be simply to use a standard observability tests on the joint system. The properties of the sub-systems of this kind of cascade do not alone determine the observability, because we can have phenomena like zero-pole cancellation which leads to a non-observable system even when all the subsystems are observable \simo{cite e.g. Gilbert:1963}. When we also account for the effect of sampling to observability, we get the following theorem.

Theorem: Assume (a) that the continuous-time joint system (A,C) is observable, and (b) the
observations are not critically sampled [ref], then the sampling full system is observable.

*** 

The aim is now to discuss the controllability and stabilizablity of state-space latent force models. We assume that the model has the form

  df/dt = A_f f + B_f C_u u + B_c c
  du/dt = A_u u + B_u w

We have the following assumptions:

1. The physical system part, without the latent force, that is

  df/dt = A_f f + B_c c

is controllable and hence stabilizable.

2. The matrix A_u in the state-space representation for the force is stable.


First of all, the stabilizability of the system is guaranteed solely by ensuring that the physical model part is stabilizable, because state-space representations of stationary GPs -- provided that they are properly formed -- are stable. Thus we have the following theorem.

[stabilizability]

The stabilizability also implies that the corresponding LQ controller is uniquely determined (Anderson & Moore, Optimal Control)

However, this is not very useful in practice, because sole stabilizability says that we might have randomly wandering subprocesses in the joint system which practically prevent us from controlling the process exactly where we wish is to go. A much stronger requirement is to require that the full system controllable. Unfortunately, it turns out that latent force models are never fully controllable in the present formulation, because we cannot control the subsystem corresponding to the GP force.

[theorem about non-controllability]

Proof. consider the system

  df/dt = A_f f + B_f C_u u + B_c c
  du/dt = A_u u

it can be seen that this is in Kalman's (ref) canonical form with u being the uncontrollable part.

In practice, the non-controllability of the force part is not a problem, as we are actually interested in controlling the physical system part of the model, not the force per se. It turns out that the physical system can be controllable even though the full system is not controllable. This result can be obtained as a corollary of so called output controllability (see, e.g., Ogata) as follows.

[theorem here that says that if the physical system is controllable, then the full system is output controllable w.r.t. to the physical system part]

Proof. consider the system

  df/dt = A_f f + B_f C_u u + B_c c
  du/dt = A_u u
      z = [I 0] [f;u]

and recall that the controllability condition for the physical system part

  df/dt = A_f f + B_c c

is that the following matrix has the full rank:

  [B_c A_fB_c  ... A_f^{n-1}B_c ]


Then this system is output-controllable (with output z) provided that the following matrix has full rank (see, e.g., Ogata):

  dx/dt = A x + B c
      z = C x

  [CB CAB CA^2B ... CA^{n-1}B ]

   CB = [I 0] [B_c;0] = B_c
  CAB = [I 0] [A_f  B_f; 0 A_u] [B_c;0] 
      = [A_f; 0] [B_c;0]
      = A_f B_c

We also have

  [A1 B1] [A2 B2]
  [0  C1] [0  C2]
  = [A1*A2 A1*B2+B1*C2;
      0    C1*C2]

hence actually

  CA^mB = A_f^m B_c

which reduces the rank condition to controllability of the physical system.

